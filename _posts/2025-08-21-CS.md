---
title: 면접에서 주로 나오는 CS 지식 질문
description: CS
author: gemini
date: 2025-08-21 17:00:00 +09:00
categories: [CS]
tags: []
math: true
mermaid: true
---

>면접관의 질문 루틴<br>
>	1. 기본 베이스가 되는 지식과 관련된 단어를 먼저 질문<br>
>	2. 해당 단어와 연관된 파생 질문이 연달아서 계속 나옴<br>
>	3. 이러한 과정을 꼬리 물기 질문이라고 하며 Depth가 깊어 질수록 높은 평가를 받을 수 있다
{: .prompt-tip}

>질문의 목적<br>
>	1. 게임 개발을 할 때도 다양한 트러블 슈팅 또는 성능 이슈가 발생하며 해당 문제에 대한 해결 실마리를 찾기 위해서 많은 베이스 지식을 알고 있어야 한다<br>
>	2. 게임 출시 전 크래시 리포트에 유저들의 OS, 하드웨어 정보를 최대한 수집하기 위한 작업을 해야 한다<br>
>	3. 게임 출시를 할 경우 유저들의 다양한 OS 및 하드웨어 환경으로 인해 성능 또는 크래시 문제가 발생되고 해당 문제들을 해결해야 한다
{: .prompt-tip}

#### OS란?

>OS(Operating System)는 컴퓨터 하드웨어 위에 사용자(다른 모든 소프트웨어) 사이에서 모든 것을 총괄하고 중재하는 핵심 시스템 소프트웨어<br>
>다시 말하면 컴퓨터 시스템의 자원을 관리하고 사용자가 컴퓨터를 사용할 수 있는 환경을 제공하는 역할을 수행한다<br>
>CPU, 메모리 같은 컴퓨터 자원은 제한적이라서 이러한 자원을 관리하는 일은 매우 중요<br>
>또한, 사용자와 컴퓨터 간 인터페이스를 제공해 사용자가 컴퓨터를 편리하게 사용할 수 있는 환경을 제공한다<br>
>대표적인 **OS로는 윈도우, 맥OS, 리눅스, 유닉스, 안드로이드** 등이 있다
{: .prompt-tip}


#### 컴퓨터의 물리적인 메모리 계층 구조

##### CPU와 메모리 구조

>CPU(Central Processing Unit)는 컴퓨터의 뇌 역할을 하며, 컴퓨터에서 프로그램을 실행하는데 필요한 연산을 처리하고 수행한다. 다른 말로 프로세서(Processor)라고 한다<br>
>메모리는 데이터를 저장하기 위한 기억 장치로, 휘발성 메모리인 주 기억 장치와 비 휘발성 메모인 **보조 기억 장치**가 있다<br>
>**주 기억 장치**는 메인 메모리를 의미하며 일반적으로 **RAM**(Random Access Memory)을 가리킨다<br>
>**보조 기억 장치**는 **SSD(Solid State Drive), HDD(Hard Disk Drive)** 등이 해당<br>
>메모리는 CPU에서 빨리 접근할 수 있도록 다음과 같이 계층 구조로 나뉜다
{: .prompt-tip}

![메모리 계층구조.png](/assets/img/posts/file_photos/메모리%20계층구조.png)

- **레지스터(Register)** : CPU가 사용자 요청을 처리하는데 필요한 데이터를 임시로 저장하는 기억 장치. CPU 내부에 존재하며 접근 속도가 빠르다
- **캐시 메모리(Cache Memory)** : CPU와 RAM 사이의 속도 차이를 해결하기 위한 기억 장치. CPU 내부에 위치하며 접근 속도가 레지스터 다음으로 빠르다. 대표적으로 3가지 타입 캐시 메모리가 존재.
	- **L1** : CPU 코어 내부에 있는 가장 작고 빠른 캐시이며, 각 코어가 독점적으로 사용을 한다
	- **L2** : L1보다 조금 크고 느리며, 마찬가지로 코어별로 할당되는 경우가 많다
	- **L3** : 가장 크고 느리지만 모든 코어가 공유하는 캐시로 , 코어 간 데이터 공유의 효율을 높여준다

![CPU 내부구조.png](/assets/img/posts/file_photos/CPU%20내부구조.png)

- **RAM(Random Access Memory)** : 컴퓨터에서 프로그램을 실행할 때 필요한 정보를 저장. CPU에서 접근 속도가 하드 디스크보다 빠르고, 휘발성 기억 장치. 보통 메모리를 지칭할 때, RAM을 의미하는 경우가 많다
- **하드 디스크(Hard Disk)** : 사용자가 필요한 데이터와 프로그램을 저장을 하는 보조 기억 장치(비휘발성 기억 장치)

|     | HDD | SDD |
| --- | --- | --- |
| 가격  | 저렴  | 비쌈  |
| 속도  | 느림  | 빠름  |


#### 캐시 히트 / 미스

##### Cache Hit/Miss

>캐시 히트와 캐시 미스는 CPU가 데이터를 요청했을 때 캐시 메모리에서 해당 데이터를 찾았는 못 찾았는지를 나타내는 개념
{: .prompt-tip}

- **캐시 히트(Cache Hit)**
	- 캐시 히트는 CPU가 필요한 데이터를 캐시 메모리에서 찾아낸 경우
	- 캐시 메모리는 주 메모리(RAM)보다 훨씬 빠르기 때문에 캐시 히트가 발생하면 데이터에 즉시 접근할 수 있기 때문에 프로그램 실행 속도가 크게 향상

- 캐시 히트의 발생 과정
	1. CPU가 특정 데이터 주소를 요청
	2. 먼저 캐시 컨트롤러가 캐시 메모리를 확인
	3. 요청된 데이터가 캐시 메모리에 존재
	4. CPU는 주 메모리에 접근할 필요 없이 캐시에서 데이터를 즉시 가져 옮

>**\<캐시 동작의 핵심 원리\>**<br>
>**시간 지역성 (Temporal Locality)** : 최근에 사용된 데이터는 가까운 미래에 다시 사용될 가능성이 높다는 원리<br>
>**공간 지역성 (Spatial Locality)** : 특정 위치의 데이터를 접근하면 그 주변에 있는 메모리 데이터들도 곧 사용될 가능성이 높다라는 원리. CPU는 이 원리에 따라 한 번에 필요한 데이터 주변의 데이터를 묶어서 ***캐시 라인 (Cache Line)*** 단위로 캐시 메모리에 통째로 가져 옮
{: .prompt-info}

- **캐시 미스 (Cache Miss)**
	- CPU가 요청한 데이터가 캐시 메모리에 없는 경우
	- 캐시 미스가 발생하면 캐시에서 데이터를 가져올 수 없으므로, CPU는 더 느린 주 메모리(RAM)에 접근해야 한다. 이 과정에서 성능 저하 발생

- 캐시 미스 발생과정
	1. CPU가 특정 데이터 주소를 요청
	2. 캐시 컨트롤러가 캐시 메모리를 확인
	3. 요청된 데이터가 캐시 메모리 없음
	4. CPU는 주 메모리에서 데이터 찾음
	5. 주 메모리에서 데이터를 가져온 후, 해당 데이터를 캐시 메모리에 저장
	6. 마지막으로 CPU는 캐시에 저장된 데이터를 사용

>**\<캐시 미스의 종류\>**<br>
>**Compulsory Miss (Cold Miss)** : 프로그램이 처음 실행될 때 발생하는 미스. 캐시가 비어있기 때에 발생하는 필연적인 미스<br>
>**Capacity Miss** : 캐시의 용량이 부족해서 발생하는 미스. 캐시에 저장할 데이터가 너무 많아 기존의 데이터를 쫓아내야 할 때를 발생<br>
>**Conflict Miss** : 캐시 메모리의 특정 위치에 여러 데이터가 매핑되어 충돌이 발생할 때 생기는 미스. **직접 매핑 (Direct Mapped)** 방식에서 주로 발생
{: .prompt-info}

- 캐시 히트를 올리기 위한 최적화 기법
	- 데이터 지향 설계 (Data Oriented Design, DOD)
		- CPU 캐시를 효율적으로 활용하여 프로그램의 성능을 극대화하는 것을 목표로 하는 소프트웨어 개발 패러다임
		- DOD는 공간적 지역성을 극대화하여 캐시 히트율을 높이는 것을 중요하게 생각
		- 대표적인 예시로 SoA 방식을 선호 [참조](https://gemini9764.github.io/posts/Data-Oriented-Design/#aos-vs-soa--%EA%B5%AC%EC%A1%B0%EC%B2%B4-%EB%B0%B0%EC%97%B4-vs-%EB%B0%B0%EC%97%B4-%EA%B5%AC%EC%A1%B0%EC%B2%B4)


#### 프로세스와 스레드

##### 프로세스(Process)

>컴퓨터에서 실행 중인 하나의 프로그램을 의미. 프로그램은 특정 작업을 수행하기 위한 명령어의 집합. OS는 프로그램을 실행하면서 디스크에 저장된 데이터를 메모리로 로드한다<br>
>프로세스는 OS로부터 독립된 메모리 영역(코드, 데이터, 스택, 힙)을 할당받으며, 다른 프로세스의 메모리 영역에 접근할 수 없다
{: .prompt-info}

- 프로세스의 메모리 영역 구조
	- 스택 (Stack)
		- 지역함수, 함수의 매개변수, 반환되는 주소값 등이 저장되는 영역
		- LIFO(Last In First Out / 후입선출) 방식으로 높은 주소값에서 낮은 주소값으로 메모리 할당되며, 영역 크기는 컴파일 때 결정됨
	- 힙(Heap)
		- 사용자에 의해 동적 메모리 할당이 일어나는 영역
		- C는 malloc, C++은 new로 할당되는 영역
		- FIFO(First In First Out / 선입선출). 낮은 주소에서 높은 주소값으로 메모리가 할당되며, 영역크기는 런타임 때 결정됨
	- 데이터(Data)
		- 전역변수, 정적변수, 배열, 구조체 등이 저장되는 영역
		- 데이터 영역은 세부적으로 BSS(Block Stated Symbol) 영역과 데이터 영역으로 나눌 수 있음
		- BSS 영역은 초기화하지 않은 변수를, 데이터 영역은 초기화한 변수를 저장
	- 코드(Code)
		- 실행할 코드가 기계어로 컴파일되어 저장되는 영역
		- 텍스트(Text) 영역이라고도 함

![메모리 영역구조.png](/assets/img/posts/file_photos/메모리%20영역구조.png)


##### 스택 오버 플로우

>**스택 오버 플로우란?**<br>
>스택에 할당된 공간을 초과하여 데이터를 저장하려 할 때 발생하는 오류
{: .prompt-info}

- 스택 오버 플로우가 발생하는 주요 원인
	1. 무한 재귀 호출
		- 함수가 자기 자신을 끝없이 호출하는 무한 재귀에 빠질 때 발생
		- 재귀 호출이 끝없이 반복되면 스택에 함수 호출 정보가 계속 쌓여서 결국 할당된 스택 메리 크기를 초과한다
	2. 지나치게 큰 지역 변수
		- 함수 내에서 매우 큰 배열 같은 지역 변수를 선언할 경우, 변수가 스택에 할당되면서 스택 공간을 너무 많이 차지하여 오버플로우가 발생할 수 있다

- 스택 오버플로우 해결 방법
	1. 종료 조건을 명확하게 한다
	2. 재귀 대신 반복문을 사용한다
	3. 과도한 스택 사이즈보다는 동적 메모리(힙) 할당을 사용한다
	4. 컴파일러 옵션을 통한 스택 사이즈 조절 (Stack Reserve Size / STACK)


##### 프로세스 간 통신 방법

>프로세스는 고유한 메모리 영역을 갖기 때문에 프로세스 간 자원을 공유해야 할 때 **IPC**해야 한다<br>
>**IPC는 Inter Process Communication**의 약자로 프로세스 간에 자원을 공유하는 방식을 나타낸다
{: .prompt-info}

- 파이프
	- 단방향 통신 방식
	- 보통 부모 자식 프로세스 관계에서 많이 사용
	- **익명 파이프(Anonymous Pipe)** : 이름이 없는 파이프로, 관계 있는 프로세스(부모 자식) 사이에서만 사용 간에 사용
	- **명명 파이프(Named Pipe)** : 이름이 있는 파이프로, 관련이 없는 프로세스들도 서로 통신 가능
	- ![파이프 예시.png](/assets/img/posts/file_photos/파이프%20예시.png)(언리얼 크래시 리포트에서 사용)

- 메시지 큐
	- 메시지들을 저장하는 큐를 사용하여 통신
	- 프로세스는 큐에 메시지를 보내거나 받는다
	- 윈도우에서 실행되는 각 애플리케이션들은 자신만의 메시지 큐를 갖고 있다
	- ![메시지 큐 예시.png](/assets/img/posts/file_photos/메시지%20큐%20예시.png)(언리얼 윈도우 메시지 사용 사례)

- 공유 메모리
	- 여러 프로세스가 접근할 수 있는 공통된 메모리 영역을 만들어 통신하는 방법
	- 데이터를 직접 읽고 쓰기 때문에 IPC 방법 중 가장 빠름
	- 여러 프로세스가 동시에 접근할 때 데이터 충돌 (Race Condition)이 발생할 수 있으므로 세마포어나 뮤텍스 같은 동기화 기술이 필수
	- ![공유 메모리 예시.png](/assets/img/posts/file_photos/공유%20메모리%20예시.png)(언리얼 엔진 윈도우 클립보드 접근)

- 소켓
	- 네트워트를 통해 통신하는 방법으로 로컬 컴퓨터 뿐만 아니라 네트워크에 연결된 다른 컴퓨터의 프로세스와 통신 할 수 있다


##### 스레드(Thread)

>**스레드**는 프로세스에서 **실제로 실행되는 흐름의 단위**를 의미<br>
>프로세스는 한 개 이상의 스레드를 갖는다<br>
>스레드는 프로세스 안에 존재하므로 프로세스의 메모리 공간을 이용하고, 지역 변수를 저장하는 스택 영역을 할당 받는다<br>
>전역 변수를 저장하는 힙 영역은 다른 스레드와 공유한다
{: .prompt-info}

![스레드.png](/assets/img/posts/file_photos/스레드.png)

- 스레드 간 공유 가능/불가능한 자원

|                  | 공유  | 설명                                                                   |
| ---------------- | --- | -------------------------------------------------------------------- |
| 스택(Stack)        | X   |                                                                      |
| 코드(Text Segment) | O   | 읽기 전용이라서 충돌 위험 없음                                                    |
| 힙(Heap)          | O   | 모든 스레드 접근 가능<br>(충돌 방지를 위한 동기화 필수)                                   |
| 데이터(Data)        | O   | 전역, 정적 변수의 경우 데이터 영역에 위치하기 때문에 모든 스레드가 접근 가능<br>Race Condition 위험 존재 |

>**Race Condition**이란?<br>
>두 개 이상의 프로세스가 공통 자원을 병행적으로 읽거나 쓰는 동작을 할 때, 공용 데이터에 대한 접근이 어떤 순서에 따라 이루어졌는지에 따라 그 실행 결과가 같지 않고 달라지는 상황<br>
>Race의 뜻 그대로, 경쟁하는 상태, 즉 두 개의 스레드가 하나의 자원을 놓고 서로 사용하려고 경쟁하는 상황을 말한다
{: .prompt-info}

- Race Condition을 막기 위한 동기화(Synchronization) 방법
	- **뮤텍스(Mutex)** : 락(lock)을 가진 스레드만이 공유 자원에 접근할 수 있게 하는 방법
	- 예시
		- 뮤텍스의 작동 방식은 화장실과 화장실 열쇠가 하나뿐인 식당과 같다
			1. 식당에는 화장실 한 칸과 화장실 문을 열 수 있는 열쇠 한 개가 있다
			2. A가 열쇠를 가지고 화장실을 간다
			3. 화장실에 가려던 B는 열쇠가 없어서 기다린다
			4. A가 화장실에서 나와 열쇠를 반납하면, 기다리던 B가 열쇠를 가지고 화장실에 간다
			- 여기서 화장실은 *공유 자원을 포함한 임계영역*을, 열쇠는 *락*을, A와 B는 *공유 자원에 접근하려는 스레드*를 의미
	- ***임계 영역에 먼저 접근한 스레드가 임계영역에 락을 결면 다른 스레드들은 해당 스레드가 락을 해제 하기 전까지 대기해야 한다***
	- ![뮤텍스.png](/assets/img/posts/file_photos/뮤텍스.png)
	- ![뮤텍스 예시.png](/assets/img/posts/file_photos/뮤텍스%20예시.png)(언리얼 Mutex 적용 예시) 

- 세마포어(Semaphore)
	- 공유 자원에 접근할 수 있는 스레드의 수를 정해 접근을 제어하는 방법
	- 예시
		1. 식당에 화장실 3칸, 화장실을 열 수 있는 열쇠는 3개가 있다
		2. A가 화장실 열쇠 하나를 가지고 화장실에 간다. 열쇠는 2개가 남는다
		3. B, C가 열쇠를 하나씩 가지고 화장실에 간다. 남은 열쇠가 없어서 D는 화장실에 가지 못한다
		4. C가 화장실에서 나와 열쇠를 돌려 놓으면, D가 화장실에 간다
		- *화장실* = 공유 자원을 포함한 임계영역
		- *A, B, C, D* = 공유 자원에 접근하려는 스레드
		- *화장실 개수(열쇠 개수)* = 공유 자원에 접근할 수 있는 스레드의 수를 제어하기 위한 정수 변수
	- ***임계 영역에 접근할 수 있는 키 n 개를 지정하고 이 중 하나를 가진 스레드만이 임계영역에 접근하게 하는 방식***
	- ![세마포어.png](/assets/img/posts/file_photos/세마포어.png)
	- ![세마포어 예시.png](/assets/img/posts/file_photos/세마포어%20예시.png)(언리얼 세마포어 적용 예시)

- 아토믹(Atomic Operations)
	- 여러 스레드가 동시에 접근하는 **단일 변수**를 **하나의 깨뜨릴 수 없는 연산**으로 처리해 안전하게 만드는 방법
	- 단순한 연산들도 컴퓨터 내부에서는 여러 단계로 쪼개져서 실행
	- x++라는 코드는 다음과 같은 세 단계로 이루어진다
		1. 메모리에서의 x의 값을 읽어온다
		2. 읽어 온 값에 1을 더한다
		3. 1을 더한 값을 다시 메모리의 x에 쓴다
	- 여러 스레드가 동시에 이 세 단계 중 하나에 접근한게 되면, 데이터가 꼬이는 Race Condition이 발생한다
	- ***임계 영역에 있는 변수에 대한 연산 자체를 쪼개지지 않는 단일 단위로 만들고 스레드만이 접근하게 하는 방식***
	- 언리얼 엔진에서는 TAtomic이 있지만 현재는 사용을 권장하지 않고, std::atomic 사용을 권장하고 있다

```
DEPRECATED! UE atomics are not maintained and potentially will be 
physically deprecated. Use std::atomic<T> for new code
```

- Critical Section
	- 멀티 스레드 환경에서 공유 자원에 대한 동시 접근을 제어하기 위해 사용되는 동기화 객체
	- C++에서 Mutex와 유사한 역할을 하지만, 단일 프로세스 내의 스레드 간 동기화에만 사용된다는 특징이 있다
	- 뮤텍스와 달리 커널 객체가 아니기 때문에 스레드 간 잠금(lock) 및 해제(unlock) 작업이 사용자 모드에서 처리된다
	- 성능이 빠르고 가볍다는 장점
	- ![Critical Section.png](/assets/img/posts/file_photos/Critical%20Section.png)(언리얼 엔진 적용 사례)

- 교착상태 (DeadLock)
	- 2개 이상의 프로세스가 각각 자원을 가지고 있으면서 서로의 자원을 요구하며 기다리는 상태
	- 교착상태 발생 4가지 필요 충분 조건
		- **상호배제 (mutual exclusion)** : 하나의 공유 자원에 하나의 프로세스만 접근할 수 있다
		- **점유와 대기 (hold and wait)** : 프로세스가 최소 하나의 자원을 점유하고 있는 상태서 추가로 다른 프로세스에서 사용 중인 자원을 점유하기 위해 대기한다
		- **비선점 (non-preemption)** : 다른 프로세스에 할당된 자원을 뺏을 수 있다
		- **환형 대기 (circular wait)** : 프로세스가 자신의 자원을 점유하면서 앞이나 뒤에 있는 프로세스의 자원을 요구한다
		- ![교착상태.png](/assets/img/posts/file_photos/교착상태.png)

>ThreadSafe란?<br>
>멀티스레드 환경에서 하나의 변수, 객체에 여러 개가 동시에 접근을 해도 문제가 없음을 의미한다
{: .prompt-info}

>좀비 프로세스와 고아 프로세스<br>
> - 좀비 프로세스<br>
>      - 자식 프로세스가 종료 되었지만 부모 프로세스가 자식 프로세스의 종료 상태를 회수하지 않았을 경우 남겨진 자식 프로세스를 말한다
> - 고아 프로세스
> 	 - 부모 프로세스가 자식 프로세스보다 먼저 종료되는 경우를 자식 프로세스를 고아 프로세스라고 한다
{: .prompt-info}


#### 콘텍스트 스위칭(Context Switching)

>OS에서 CPU는 하나의 프로세스만 처리할 수 있으므로 멀티 프로세스를 처리하려면 CPU 스케줄러에 의해 인터럽트(Interrupt)가 발생하면서 콘텍스트 스위칭이 이뤄진다<br>
>여기에서 콘텍스트(Context)는 CPU가 처리하는 프로세스 정보를 의미한다<br>
>멀티 프로세스 환경에서 CPU가 처리 중인 프로세스의 정보를 바꾸는 것을 **콘텍스트 스위칭(Context Switching)** 이라고 한다
{: .prompt-tip}

- 콘텍스트 스위칭 과정
	- CPU가 P1을 처리하던 중 OS에 의해 인터럽트가 발생
	- P1은 유휴 상태로 변하고 스케쥴러는 레지스터에 있는 처리 중인 작업 정보를 P1의 PCB에 저장한다
	- P2의 **PCB(Process Control Block)** 에 있는 정보를 가져와 레지스터에 로드하고 CPU는 P2를 처리하기 시작한다
	- P1의 정보를 P1의 PCB에 저장하고 P2의 PCB에 저장된 정보를 레지스터에 로드하는 동안 CPU는 아무 일도 못하게 된다. 이런 과정을 통해서 CPU는 '오버헤드가 발생한다'라고 표현한다

>**인터럽트(Interrupt)란?**<br>
>CPU에서 프로세스를 처리하다가 입출력 관련 이벤트가 발생하거나 예외 상황이 발생할 때 이에 대응 할 수 있게 CPU에 처리를 요청하는 것을 의미<br>
>대표적인 인터럽트 발생<br>
>	입출력이 발생할 때<br>
>	CPU 사용 시간이 만료 되었을때<br>
>	자식 프로세스를 생성할 때<br>
{: .prompt-tip}

> **PCB(Process Control Block)란?**<br>
> OS가 프로세스를 관리하는데 필요한 모든 정보를 담고 있는 핵심 자료구조<br>
> 각각의 프로세스는 고유한 PCB를 가지며, 프로세스가 생성될 때 함께 만들어지고 종료되면 사라진다<br>
> 프로세스의 '신분증' 이자 '작업일지' 와 같아서 OS가 어떤 프로세스를 실행할 지, 어디까지 실행했는지 파악하는 데 사용
{: .prompt-tip}

![콘텍스트 스위칭.png](/assets/img/posts/file_photos/콘텍스트%20스위칭.png)


#### 가상 메모리(Virtual Memory)

>사용자가 프로그램을 실행하면 OS는 디스크에 저장된 데이터를 메모리로 로드한다<br>
>하지만 메모리 공간은 한정되어 있고, 사용자는 동시에 많은 프로그램을 실행하길 원한다<br>
>이런 메모리 공간의 한계를 극복하기 위해 ***가상 메모리***라는 개념이 등장했다<br>
>***가상 메모리***는 프로세스의 일부만 메모리에 로드하고, 나머지는 디스크에 둔 상태로 프로세스를 실행하는 방식<br>
>사용자는 프로세스 전체가 메모리에 로드된 것처럼 보이지만, 실제는 전체가 로드된 것이 아니서 가상 메모리라고 한다. 실제 물리 메모리보다 훨씬 큰 메모리 공간을 사용자에게 제공하는 기술이다<br>
>실제로 실행에 필요한 부분 (페이지 또는 세그먼트)만 메모리에 로드하고 나머지는 하드 디스크 같은 보조 기억 장치에 보관을 한다. 물리 메모리 공간이 부족할 경우 디스크를 대신 사용한다.
{: .prompt-info}

![가상 메모리.png](/assets/img/posts/file_photos/가상%20메모리.png)

- 가상 메모리의 장점
	- 프로그램이 메모리 크기에 대한 제약을 덜 받을 수 있다
	- 동시에 많은 프로그램을 실행하므로 CPU 이용률과 처리율을 높일 수 있다
	- 필요한 영역만 메모리에 로드해 스와핑 횟수를 줄여서 프로그램 실행 속도를 높일 수 있다

>**가상 주소와 물리 주소의 차이점**<br>
>가상 메모리 시스템에서는 주소를 두 가지로 구분<br>
>	- **가상 주소(Virtual Address)** : CPU가 생성하는 주소로, 프로그램이 사용하는 논리적인 주소
>	- **물리 주소(Physical Address)** : 실제 메모리(RAM)에 존재하는 주소
{: .prompt-tip}

- 메모리 관리 장치(MMU, Memory Management Unit)
	- 두 주소 사이의 변환을 담당
	- CPU가 가상 주소를 요청하면, MMU가 이를 물리 주소로 변환하여 실제 메모리에 접근하게 된다

>**페이지(page)와 프레임(Frame)**<br>
>가상 메모리 시스템은 메모리를 일정한 크기로 나눈 블록 단위로 관리한다<br>
>	- **페이지(Page)** : 가상 메모리 공간을 나눈 고정된 크기의 블록<br>
>	- **프레임(Frame)** : 물리 메모리(RAM)를 나눈 고정된 크기의 블록<br>
>일반적으로 페이지와 프레임은 같은 크기를 가진다. 윈도우 11 기준으로 4KB(4096 Byte) 단위로 나눌 수 있다
{: .prompt-info}

>**페이징(Paging)**<br>
>가상 메모리를 구현하는 가장 대표적인 방법. 가상 주소 공간의 페이지를 물리 메모리의 프레임에 매핑(Mapping)하는 기법<br>
>매핑 과정<br>
>	- 각 프로세스는 자신의 페이지 테이블(Page Table)을 가진다<br>
>	- 페이지 테이블은 가상 메모리의 페이지 번호와 물리 메모리의 프레임 번호를 연결해 준다<br>
>	- CPU가 가상 주소를 생성하면, MMU는 페이지 테이블을 참조하여 해당하는 물리 주소를 찾는다
{: .prompt-info}

>**페이지 폴트(Page Fault)**<br>
>CPU가 접근하려는 가상 주소에 해당하는 페이지가 현재 물리 메모리에 없는 경우 발생<br>
>처리과정<br>
>	1. 필요한 페이지가 물리 메모리에 있는지 없는 지를 페이지 테이블에서 확인. 없는 것(페이지 부재)이 확인되면 CPU는 운영체제에 인터럽트를 보낸다. 그리고 페이지 폴트가 발생하면 i를 반환한다<br>
>	2. i를 반환하면 OS는 참조하려는 페이지의 주소값이 유효한지 않은지 아니면 메모리에 로드되지 않은 영역인지 판단한다<br>
>	3. 필요한 페이지가 메모리에 로드되지 않은 영역이라면 디스크에서 해당 영역을 찾는다<br>
>	4. 디스크에서 해당 페이지 영역을 스왑인 한다. 이때 물리 메모리에 비어 있는 프레임이 있으면 페이지를 해당 영역에 바로 로드한다. 만약 비어 있는 프레임이 없으면 페이지 교체 알고리즘을 호출해 기존에 로드된 페이지를 디스크로 스왑 아웃한 후 새로운 페이지를 로드한다<br>
>	5. 페이지 테이블에서 새로 로드한 페이지의 값을 v로 변경한다<br>
>	6. 다시 중단되었던 명령어를 실행한다<br>
>![페이지 폴트.png](/assets/img/posts/file_photos/페이지%20폴트.png)
{: .prompt-info}

- 페이지 교체 알고리즘
	- 물리 메모리가 가득 찼을 때, 새로운 페이지를 넣기 위해 어떤 프레임의 디스크로 내보낼지 결정하는 알고리즘
	- **FIFO(First-In, First-Out)**
		- 가장 먼저 메모리에 들어온 페이지를 먼저 내보낸다
	- **LRU(Least Recently Used)**
		- 가장 오랫동안 사용하지 않은 페이지를 내보낸다
		- 최근에 사용된 페이지는 앞으로도 사용될 확률이 높다는 가정을 기반으로 한다
	- **LFU(Least Frequently Used)**
		- 사용 빈도가 가장 낮은 페이지를 보낸다


#### 메모리 단편화 (Memory Fragmentation)

>컴퓨터 메모리에서 공간이 비어있지만, 그 공간들이 너무 작게 흩어져 있어 실제로는 아무것도 할당할 수 없는 상태를 말한다<br>
>쉽게 말해, 메모리 공간이 여러 조각으로 나뉘어 있어 사용 가능한 총 용량은 충분하지만, 연속된 큰 공간이 없어서 효율적으로 사용하지 못하는 현상<br>
>- 원인
>	- 프로그램이 크기가 다른 여러 메모리 덩어리를 힙에서 요청
>	- 이 덩어리들이 사용 후 해제되면, 원래 있던 자리에 빈 공간이 생긴다
>	- 이 빈 공간들이 너무 작고 흩어져 있어, 다음에 오는 큰 메모리 요청을 수용할 수 없게 된다
{: .prompt-info}

- 단편화의 종류
	- 외부 단편화
		- 힙에 빈 공간이 충분하지만, 이 공간들이 여러 개의 작은 조각으로 흩어져 있어 연속된 큰 공간을 필요로 하는 새로운 메모리 요청을 처리할 수 없는 현상
	- 내부 단편화
		- 할당된 메모리 블록 내에서 실제 사용되는 공간보다 남은 여분의 공간이 있는 경우
		- 주로 메모리 할당기가 정해진 크기 단위 (ex. 8바이트, 16바이트)로 메모리를 관리할 때 발생
		- 예시로, 사용자는 7바이트만 필요하지만 실제 메모리 할당기를 통해서 내부에서는 8바이트 생성되어 1바이트가 낭비가 되게 된다

- 단편화 해결 방안
	- **메모리 풀(Memory Pool)**
		- 미리 정해진 크기의 메모리 블록을 여러 개 확보해 놓고 할당 요청이 들어올 때마다 풀에서 꺼내 쓰는 방식
		- 동일한 크기의 객체를 반복적으로 다룰 때 외부 단편화를 크게 줄일 수 있다
	- **가비지 컬렉션(Garbage Collection)**
		- 더 이상 사용하지 않는 메모리를 자동으로 회수하는 기술
		- 일부 가비지 컬렉터는 **메모리 압축(compaction)** 기능을 포함하여 흩어진 빈 공간을 한 곳으로 모아 외부 단편화를 줄여준다
	- **스마트 포인터와 할당 전략**
		- 스마트 포인터를 사용하여 메모리 누수를 방지하고, 특정 할당 전략을 사용하여 단편화를 줄일 수 있다
		- 예시로 힙의 특정 영역에만 특정 객체를 할당하는 방식이 있다

- 언리얼 엔진 메모리 관리 전략
	- 언리얼 엔진은 인텔사의 **Intel oneTBB(OneAPI Threading Building Blocks)** 라이브러리를 사용하여 메모리 관리를 한다
	- **Intel oneTBB**
		- 인텔이 개발한 C++ 라이브러리
		- 멀티코어 프로세스의 성능을 최대한 활용할 수 있도록 병렬 프로그래밍을 쉽게 만들어 준다
		- 여러 스레드가 동시에 메모리에 접근할 때 효율적인 **스레드-안전 메모리 할당기**가 포함되어 있다
	- **동일 크기 블록 관리**
		- TBB는 요청된 메모리 크기를 여러 개의 버킷(Bucket)으로 나누어 관리한다
		- 예를 들어, 16바이트 요청은 16바이트 버킷에서, 64바이트 요청은 64바이트 버킷에서 처리하는 방식
		- 이런 식으로 비슷한 크기의 할당 요청이 연속적으로 처리되어 외부 단편화를 줄이는 효과과 있다
	- **메모리 압축(Compaction)**
		- TBB 할당기는 메모리 블록을 해제할 때, 인접한 빈 공간을 합쳐 더 큰 빈 공간으로 만드는 기능(Coalescing)을 가지고 있다
		- 장기적으로 힙 내부에 흩어져 있는 작은 조각들을 줄여 외부 단편화를 완화하는 기능을 한다
	- **내부 단편화 최소화**
		- TBB는 다양한 크기 요청을 처리하면서도 최소한의 여분 공간이 남도록 최적화된 할당 전략을 사용한다
		- 이를 통해 내부 단편화를 줄일 수 있다